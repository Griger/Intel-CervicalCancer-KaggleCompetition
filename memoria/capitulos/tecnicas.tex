\section{Técnicas de clasificación}

\subsection{OVO}

Tras los experimentos realizados anteriormente pasamos a descomponer nuestro problema multiclase con un esquema OVO para ello entrenamos tres redes neuronales distintas, la elección de la red a entrenar la hicimos en base a los experimentos anteriores, con lo cual para cada uno de los tres problemas binarios entrenamos una ResNet 50 modificando sus capas \textit{fully connected} para que tengamos dos salidas en lugar de tres como anteriormente.\\

Se generaron, para evitar problemas con las etiquetas de cada clase, de modo que se estuviesen siempre en el conjunto {0,1} y ahora simplemente entrenamos cada una de las redes sobre cada uno de los conjunto creados, nuevamente con 10 \textit{epochs} de \textit{transfer learning} y otras 50 de \textit{fine tunning}. Una vez se han entrenado cada una de las redes pasamos al esquema de agregación de los resultados, las probabilidades, obtenidas para cada una de las clases. Señalar que para estos esquemas se ha supuesto que cada uno de las redes, para aquella clase que ignoran que existe, dan como probabilidad el valor 0.\\

El primer esquema que se nos ocurrió fue el más simple de todos, simplemente para cada clase la probabilidad asignada será \emp{la media} de la probabilidad para dicha clase asignada por cada una de las tres redes neuronales. No obstante este esquema tiene algo que no nos gusta y es que si por ejemplo tenemos las siguientes probabilidades:

\begin{table}[H]
\centering
\caption{Ejemplo de probabilidades}
\label{my-label}
\begin{tabular}{|c|c|c|c|}
\hline
Clasificador \textbackslash Clase & Tipo 1 & Tipo 2 & Tipo 3 \\ \hline
1-2                               & 1      & 0      & 0      \\ \hline
1-3                               & 1      & 0      & 0      \\ \hline
2-3                               & 0      & 0.5    & 0.5    \\ \hline
\end{tabular}
\end{table}

Entonces a esta imagen, usando como esquema de agregación la media, tenemos las siguientes probabilidades:

\begin{table}[H]
\centering
\caption{Probabilidades de la media}
\label{my-label}
\begin{tabular}{|c|c|c|}
\hline
Tipo 1 & Tipo 2 & Tipo 3 \\ \hline
0.67   & 0.19   & 0.14   \\ \hline
\end{tabular}
\end{table}

Como vemos mientras que dos clasificadores nos dan una confianza del 100\% en que la imagen es del Tipo 1, como el clasificador 2-3 da como probabilidad para esa clase el 0, puesto que no conoce el Tipo 1, y aunque ese clasificador no tiene certidumbre sobre la pertenencia de la imagen al Tipo 2 o al Tipo 3, dando probabilidad 0.5 para ambas, lo que ocurre es que la probabilidad que le damos a la imagen para el Tipo 1 es de 0.67. Esto nos parecía algo injusto y nos gustaría un esquema que tuviese en cuenta este tipo de escenarios, dando mayor peso a los dos primeros clasificadores que al que no está seguro sobre la clase a la que pertenece la imagen.\\

Por lo que acabamos de exponer decidimos probar con otro esquema, para ello leímo un artículo, en el que participa como autor el profesor Francisco Herrera y que referenciamos en la bibliografía de esta práctica, en el que se describen distintos esquemas de agregación para binarización de problemas OVO y OVA. Entre todos los esquemas expuestos nos decantamos por el llamado \emp{LVPC}, el cual se dice en el artículo que, en el caso en estar ante un problema con clasificadores binarios normalizados, es decir, clasificadores que para una clase den la probabilidad $\alpha$ y para la otra clase den su opuesto, $1 - \alpha$, entonces estamos antes un esquema establece una votación ponderada que penaliza a los clasificadores que no tienen confianza en su elección respecto a la pertenencia de la instancia a una de las dos clases que distingue.\\

Este esquema funciona como sigue, si llamamos $r_{ij}$ a la probabilidad que da el clasificador binario para las clases $i$ y $j$ para la pertenencia de una instancia a la clase $i$, y $r_{ji}$ a su análogo para la clase $j$. Entonces se calculan los siguientes términos:

\begin{center}
$P_{ij} = r_{ij} - min\lbrace r_{ij}, r_{ji} \rbrace$\\
$P_{ji} = r_{ji} - min \lbrace r_{ij}, r_{ji} \rbrace$\\
$C_{ij} = min\lbrace r_{ij}, r_{ji} \rbrace$\\
$I_{ij} = 1 - max\lbrace r_{ij}, r_{ji} \rbrace$
\end{center}

donde, como explica el artículo $C_{ij}$ es el grado de conflicto (el grado en el que ambas clases son escogidas por el clasificador), $I_{ij}$ es el grado de ignorancia que tiene el clasificador (el grado en el que ninguna de las dos clases es escogida por el clasificador) y finalmente $P_{ij}$ y $P_{ji}$ es el grado de preferencia del clasificador hacia cada una de las dos clases. Entonces una vez que hemos calculado esto para cada instancia el esquema asigna la siguiente clase a esta instancia:

\begin{center}
$\underset{i = 1,...,m}{argmax} \underset{1 \leq j \neq i \leq m}{\sum} P_{ij} + \frac{1}{2} C_{ij} + \frac{N_i}{N_i + N_j}I_{ij}$
\end{center}

Donde $N_i$ es el número de instancias en nuestro conjunto de entrenamiento de la clase $i$. En nuestro caso, como realizamos un \textit{data augmentation online} entonces hemos supuesto que se mantienen las proporciones del conjunto de entrenamiento original, las del conjunto inicial y las adicionales para cada clase. Por otro lado como no queremos dar un resultado absoluto, es decir, dar probabilidad 1 a una clase y 0 al resto, lo que hemos hecho es en lugar de tomar el $argmax$ de las 3 sumatorias que se calculan es usar directamente el resultado de las sumatorias, dividido por 3, ya que nos encontramos con que el valor de las tres sumatorias sumaban 3 siempre, con lo que hemos dividido por tres para que sumen 1.

\subsection{Extracción de características con una CNN}



\subsection{Extracción de características con técnicas convencionales}

\subsubsection{HOG}

\subsubsection{ORB}