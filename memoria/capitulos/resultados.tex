\section{Presentación y discusión de resultados}

Los primeros experimentos que se realizaron fue empleando la técnica de \emp{\textit{learning from scratch}}, es decir, diseñar y entrenar una red desde cero. Para ello se empleó la red que se definía en un script de Kaggle en un \textit{kernel} de esta competición y que se enlaza en la bibliografía. Aunque debido a nuestra inexperiencia en el ámbito del \textit{deep learning} no supimos cómo mejorar nuestra red o hacer su entrenamiento más efectivo de cara a la clasificación, si que pudimos observar algunos resultados bastante interesantes y que se explican a continuación.\\

En esta fase hicimos pruebas tanto con las imágenes rescaladas a 256x256 como a 32x32, este último rescalado fue algo que se hizo para simplemente poder realizar unas primeras pruebas sin demasiado tiempo de cómputo, no obstante resultaron ser unos experimentos más valiosos de lo que esperábamos. Y es que como podemos ver en \autoref{soluciones} se obtuvieron mejores resultados trabajando con imágenes de 32x32 que con las de mayor tamaño.\\

Realmente nosotros esperábamos que los resultados fuesen peores, de hecho una de nuestras preocupaciones de cara a afrontar la práctica era tener que reescalar las imágenes a un tamaño más reducido si los tiempos de cómputo eran demasiado elevados, esta preocupación se debía a que pensamos que cuanto más pequeña hiciésemos la imagen más información estaríamos perdiendo. Realmente lo que creemos que está influyendo en estos resultados en la simplicidad de la red que estamos estuadiando.\\

Lo que puede estar ocurriendo es que al tener una red tan simple ésta no sea capaz de extraer todos los matices que puede haber en una imagen y que por tanto la red se esté \textit{saturando de información} y por consiguiente esté sobreaprendiendo, por esto estamos obteniendo estos resultados. De hecho esto se observa bien cuando intentamos usar además del conjunto de entrenamiento base las imágenes adiconales que se facilitan en Kaggle. Mientras que en el caso de trabajar con imágenes pequeñas se mejora el score obtenido para las imágenes de 256x256 la red se \textit{satura} aún más y el score empeora. Observemos que el \textit{accuracy} en el conjunto de validación (un 40\% del conjunto de entrenamiento) no parece dar mucha información, en la mayoría de casos es similar, y cuando parece que nuestra red está sobreaprendiendo, en la \textit{submission} 3, el resultado obtenido es mejor que en el caso de las imágenes de 256x256 con un \textit{val\_acc} menor.\\

Distinto es cuando pasamos a hacer \emp{\textit{data augmentation}} siendo ahora la red entrenada con las imágens más grande la que mejores resultados obtiene, esto puede deberse a que al proporcionarla a la red, en cada \textit{epoch}, nuevos ejemplos conseguimos que el sobreaprendizaje que antes estábamos sufriendo se suavice pues ahora tiene más ejemplos sobre los que extraer características y por tanto puede realizar un aprendizaje más diversificado con su limitada capacidad por tratarse de un red relativamente simple. Si que vemos que cuando aumentamos el número de nuevas imágenes se generan, en la \textit{submission} 11, el resultado empeora ligéramente, quizás ya estemos nuevamente saturando la red al dar demasiados ejemplos que, por mucho que intentemos modificarlos a través de transformaciones aleatorias, no dejan de ser imágenes del conjunto de train original.



